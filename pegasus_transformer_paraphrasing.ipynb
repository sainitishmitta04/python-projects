{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DataScienceTask.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNf3PLTmpesCZpa5AuwZj2G",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sainitishmitta04/python-projects/blob/main/pegasus_transformer_paraphrasing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Rewriting the sentence into formal,casual ---> Paraphrasing"
      ],
      "metadata": {
        "id": "JkPY3ldIKnYa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **PEGASUS** **Transformer**"
      ],
      "metadata": {
        "id": "wHuU6o57K6fI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### The PEGASUS modelâ€™s pre-training task is very similar to summarization, i.e. important sentences are removed and masked from an input document and are later generated together as one output sequence from the remaining sentences, which is fairly similar to a summary"
      ],
      "metadata": {
        "id": "glHNP6LBL9uM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### I have used PEGASUS model to derive paraphrases from an input sentence,and we can compare how it is different from the input sentence"
      ],
      "metadata": {
        "id": "9Mi6eNCSMXT2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### PEGASUS is an acronym for Pre-training with Extracted Gap-sentences for Abstractive Summarization Sequence-to-sequence models\n",
        "\n",
        "### PEGASUS model used here is from Huggingface's transformers library"
      ],
      "metadata": {
        "id": "FTornRlUNlcQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Installing dependencies**"
      ],
      "metadata": {
        "id": "DO8dMHqfNJka"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Ignoring unncessary warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "P0nvcUPeKbpJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PgFFI9-fCX0P",
        "outputId": "310f0bc3-7b99-40ed-9653-ed1bc6a68357"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: sentence-splitter in /usr/local/lib/python3.7/dist-packages (1.4)\n",
            "Requirement already satisfied: regex>=2017.12.12 in /usr/local/lib/python3.7/dist-packages (from sentence-splitter) (2022.6.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install sentence-splitter"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uz1ioGJ5CntS",
        "outputId": "878e5976-177e-40b1-8cc4-aee3be9ee563"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.20.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.4)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.8.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install SentencePiece"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2t1YowVYDcXZ",
        "outputId": "5bbae75f-9881-4867-b879-41650be49262"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: SentencePiece in /usr/local/lib/python3.7/dist-packages (0.1.96)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Setting Up the PEGASUS transformer Model**"
      ],
      "metadata": {
        "id": "FO1rN9wbNB00"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import PegasusForConditionalGeneration, PegasusTokenizer\n",
        "\n",
        "model_name = 'tuner007/pegasus_paraphrase'\n",
        "torch_device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "tokenizer = PegasusTokenizer.from_pretrained(model_name)\n",
        "model = PegasusForConditionalGeneration.from_pretrained(model_name).to(torch_device)\n",
        "\n",
        "def get_response(input_text,num_return_sequences):\n",
        "  batch = tokenizer.prepare_seq2seq_batch([input_text],truncation=True,padding='longest',max_length=60, return_tensors=\"pt\").to(torch_device)\n",
        "  translated = model.generate(**batch,max_length=60,num_beams=10, num_return_sequences=num_return_sequences, temperature=1.5)\n",
        "  tgt_text = tokenizer.batch_decode(translated, skip_special_tokens=True)\n",
        "  return tgt_text"
      ],
      "metadata": {
        "id": "xnu49ztHCseK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Testing the Model**"
      ],
      "metadata": {
        "id": "Baq1hupAM8mP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#test input sentence\n",
        "text = \"I was ranked 2nd as a contributor to the scoial scheduler,with 3 PRs and 55 points.\""
      ],
      "metadata": {
        "id": "P_ehJ0FeDZBh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#printing response\n",
        "get_response(text,5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4E9tOYOwEzHz",
        "outputId": "42f1afd3-44cc-4156-cbaa-8b5d3373305c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['I received 3 PRs and 55 points as a contributor to the scheduler.',\n",
              " 'I was ranked 2nd as a contributor to the scheduler, with 3 PRs and 55 points.',\n",
              " 'I was a contributor to the scheduler with 3 PRs and 55 points.',\n",
              " 'I was ranked 2nd as a contributor, with 3 PRs and 55 points.',\n",
              " 'I was ranked 2nd as a contributor to the scheduler with 3 PRs and 55 points.']"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### As we can notice, because we had set the number of responses to 5, we got five different paraphrase responses by the model"
      ],
      "metadata": {
        "id": "6EJ1s2Unga3P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "get_response(text,10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-I9ojFkjGuEq",
        "outputId": "52fd75d9-9200-4566-a82c-bbc4ffa53b9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['I received 3 PRs and 55 points as a contributor to the scheduler.',\n",
              " 'I was ranked 2nd as a contributor to the scheduler, with 3 PRs and 55 points.',\n",
              " 'I was a contributor to the scheduler with 3 PRs and 55 points.',\n",
              " 'I was ranked 2nd as a contributor, with 3 PRs and 55 points.',\n",
              " 'I was ranked 2nd as a contributor to the scheduler with 3 PRs and 55 points.',\n",
              " 'I received 3 PRs and 55 points for being a contributor to the scheduler.',\n",
              " 'I was ranked 2nd as a contributor to the scheduler and received 3 PRs and 55 points.',\n",
              " 'I was ranked 2nd as a contributor and had 3 PRs and 55 points.',\n",
              " 'I was ranked 2nd as a contributor to the scheduler and had 3 PRs and 55 points.',\n",
              " 'I was ranked 2nd as a contributor to the scheduler.']"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hence, we have rewritten the sentence into formal,casual format"
      ],
      "metadata": {
        "id": "0NfjwxFsguqU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Similarly, we can input a paragraph instead of a single sentence and splits into a list of sentences and can perform the same operation to obtain the rewritten format of the paragraph"
      ],
      "metadata": {
        "id": "zrN4D65Dg0dT"
      }
    }
  ]
}